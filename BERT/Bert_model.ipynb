{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90178d40-e1f9-4302-adeb-b82dbdb79d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  7 21:51:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.77.01              Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   32C    P8             15W /  240W |    3028MiB /   8192MiB |     19%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        31      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A       567      C   /python3.11                                 N/A      |\n",
      "|    0   N/A  N/A       953      C   /python3.11                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf908596-2440-4dd7-8e4f-4eeb6a155e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch, time, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from src.Preprocessing import preprocessing_dataframe\n",
    "from src.DataLoader import DataLoaderBert\n",
    "from src.Model import Bert_FineTuned\n",
    "from src.Callback import EarlyStopping\n",
    "from src.Training import model_train, model_eval\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_LABELS = 5\n",
    "RANDOM_SEED = 23\n",
    "VOCAB_PATH = \"vocab_file.txt\"\n",
    "\n",
    "DATA_PATH = os.path.join(\"data\", \"datos.xlsx\")\n",
    "DATA_EXT_PATH = os.path.join(\"data\", \"reviews_ext.xlsx\") \n",
    "DATA_SIN = os.path.join(\"data\", \"datos_sinonimos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593aae64-766d-47fe-9684-daf2c38a1c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6052, 2), (2220, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(DATA_PATH)\n",
    "column_name_rev = df.columns.to_list()[len(df.columns.to_list())-1]\n",
    "columns_to_keep = df.columns.to_list()[:2]\n",
    "\n",
    "df_revisado = df[df[column_name_rev] == 'Revisado'][columns_to_keep]\n",
    "df_revisado_eq = preprocessing_dataframe(df_revisado, False)\n",
    "df_revisado.shape, df_revisado_eq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a7e152-57e1-42cc-8ec7-73acc09a22ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33015, 2), (35235, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ext = pd.read_excel(DATA_SIN)[columns_to_keep]\n",
    "df_ext_eq = preprocessing_dataframe(df_ext, False)\n",
    "\n",
    "df_eq = pd.concat([df_revisado_eq, df_ext_eq], axis=0)\n",
    "\n",
    "df_ext_eq.shape, df_eq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a086db-7e6a-451d-a50d-aff5d64b8a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24664, 5285, 5286)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train , df_test = train_test_split(df_eq, test_size=0.3, random_state = RANDOM_SEED)\n",
    "df_val , df_test = train_test_split(df_test, test_size=0.5, random_state = RANDOM_SEED)\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb921c9-74e1-46bf-8d9e-3e5329f9b2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_model = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = Bert_FineTuned(name_model, True, NUM_LABELS, DROPOUT).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join('model', 'bestBert.bin'), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "782ec91b-f4f8-4b65-9ed5-104b092b7fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(review):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "    encoding = tokenizer.encode_plus(review,\n",
    "                                          add_special_tokens=True, #Añade los tokens especiales que necesita BERT, [CLS] + [SEP]\n",
    "                                          padding='max_length',  #Añade el pad para que todas las secuencias tengan la misma longitud\n",
    "                                          truncation=True, #Trunca las secuancias más largas de 512, el BERT solo permite 512 tokens\n",
    "                                          max_length=512,\n",
    "                                          return_token_type_ids=False,  #Devuelve si un token pertenece a la primera o a la segunda secuencia\n",
    "                                          return_attention_mask=True,\n",
    "                                          return_tensors='pt')\n",
    "\n",
    "    inputs_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    output_model = model(inputs_ids, attention_mask)\n",
    "    preds = torch.argmax(output_model, dim = 1).tolist()\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0fad7c-bae8-4fb5-a462-6da1b6487bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = 'tenía ganas de ir a comer , me habían hablado súper bien del restaurante . si que es verdad , que el precio del menú del día me parece bastante excesivo 16 , 90 € . es cierto que la calidad , es buena , pero las cantidades no son muy abundantes para el precio que tiene el menú . el menú consta de 4 primeros 4 segundos y 3 postres , y muchos de los platos se repiten asiduamente en la carta . el trato normal , amables . la verdad , que no sería un localización al que desee volver , si se tercia pues iré , pero no especialmente . muy mal trato por pedazo de la camarera . eramos 5 ( con dos niños ) y nos pusieron en una mesa de dos , porque decían que las otras estaban reservadas . cuando llega nueva gente , la ponen en las otras mesas sin tener reserva . como íbamos con dos niños no iban a gastar dos mesas en nosotros . así nos lo ha dicho la camarera ( nuestros hijos también comen ) . nos hemos levantado e ido .'\n",
    "get_predict(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d419a-8325-4220-9c59-ffecab14f544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
