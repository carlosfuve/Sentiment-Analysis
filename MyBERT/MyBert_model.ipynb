{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08ace89-ae6e-491f-900e-abdbd6561db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  7 21:59:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 565.77.01              Driver Version: 566.36         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   32C    P8             14W /  240W |    3659MiB /   8192MiB |     19%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        31      G   /Xwayland                                   N/A      |\n",
      "|    0   N/A  N/A       567      C   /python3.11                                 N/A      |\n",
      "|    0   N/A  N/A       953      C   /python3.11                                 N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c427dce-20c3-4086-9c42-11224dff3d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch, os, time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from src.Preprocessing import preprocessing_dataframe\n",
    "from src.Tokenizer import MyTokenizer\n",
    "from src.DataLoader import DataLoaderBert\n",
    "from src.Model import MyBert, Bert_FineTuned\n",
    "from src.Callback import EarlyStopping\n",
    "from src.Training import model_train, model_eval\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_LABELS = 5\n",
    "RANDOM_SEED = 23\n",
    "VOCAB_PATH = \"vocab_file.txt\"\n",
    "\n",
    "\n",
    "DATA_PATH = os.path.join(\"data\", \"datos.xlsx\")\n",
    "DATA_EXT_PATH = os.path.join(\"data\", \"reviews_ext.xlsx\") \n",
    "DATA_SIN = os.path.join(\"data\", \"datos_sinonimos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4089512-d10d-478d-9485-8032157410a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6052, 2), (2220, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(DATA_PATH)\n",
    "column_name_rev = df.columns.to_list()[len(df.columns.to_list())-1]\n",
    "columns_to_keep = df.columns.to_list()[:2]\n",
    "\n",
    "df_revisado = df[df[column_name_rev] == 'Revisado'][columns_to_keep]\n",
    "df_revisado_eq = preprocessing_dataframe(df_revisado, False)\n",
    "df_revisado.shape, df_revisado_eq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15311081-9351-41a6-a5ad-afb913e7f239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33015, 2), (35235, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ext = pd.read_excel(DATA_SIN)[columns_to_keep]\n",
    "df_ext_eq = preprocessing_dataframe(df_ext, False)\n",
    "\n",
    "df_eq = pd.concat([df_revisado_eq, df_ext_eq], axis=0)\n",
    "\n",
    "df_ext_eq.shape, df_eq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c4f2a6-7e7e-465d-83b2-aab25aaba326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24664, 5285, 5286)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train , df_test = train_test_split(df_eq, test_size=0.3, random_state = RANDOM_SEED)\n",
    "df_val , df_test = train_test_split(df_test, test_size=0.5, random_state = RANDOM_SEED)\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1899924-4830-4737-bc40-391d97d399bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = MyTokenizer(VOCAB_PATH)\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 4\n",
    "VOCAB_SIZE = 20000\n",
    "DROPOUT = 0.1\n",
    "EMBED_DIM , ATT_HEADS, D_FF = 768, 12, 3072\n",
    "\n",
    "model = MyBert(VOCAB_SIZE, MAX_LEN, EMBED_DIM, ATT_HEADS, D_FF, DROPOUT, NUM_LABELS, device, N=1).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join('model', 'bestMyBert.bin'), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7fa8cd-23e7-4802-8c0c-78552f014a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader, device):\n",
    "    model.eval()\n",
    "    review_texts = []\n",
    "    values, predictions, values_prob, predictions_prob = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            texts = d[\"review_text\"]\n",
    "            review_texts.append(' '.join(texts))\n",
    "\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            values.extend(targets.tolist())     \n",
    "\n",
    "            output_model = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(output_model, dim = 1)\n",
    "            predictions.extend(preds.tolist())      \n",
    "            \n",
    "            output_model = F.softmax(output_model,dim=1)\n",
    "            out_targ = output_model[torch.arange(targets.size(0)), targets]\n",
    "            values_prob.extend(out_targ.tolist())\n",
    "            out_preds = output_model[torch.arange(preds.size(0)), preds]\n",
    "            predictions_prob.extend(out_preds.tolist())\n",
    "\n",
    "    values_prob = [round(num, 3) for num in values_prob]\n",
    "    predictions_prob = [round(num, 3) for num in predictions_prob]\n",
    "    return review_texts, values, predictions, values_prob, predictions_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac564c0-2c24-480e-b3aa-04bb8e479f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval_torch = DataLoaderBert(df_test['Review'].to_list(), df_test['Score_G'].to_list(),tokenizer, MAX_LEN, include_raw_text=True)\n",
    "eval_dataloader = DataLoader(dataset_eval_torch, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97b71cb-38db-46fd-add6-b55530229ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pedí unos caracoles y la verdad es que se pasaron de coccion , bastante secos y duros , la salsa brava y las patatas muy mejorables , por el resto el váter correcto y los precios un poco elevados , local amplio , tipico para hacer cenas de grupos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2, 0.371, 0.371)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews, values, predictions, values_prob, predictions_prob = get_predictions(model, eval_dataloader, device)\n",
    "print(reviews[0])\n",
    "values[0], predictions[0], values_prob[0], predictions_prob[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18fd9e67-4917-4633-be4b-ab92048c962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_model = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(name_model)\n",
    "MAX_LEN = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model_bert = Bert_FineTuned(name_model, True, NUM_LABELS, DROPOUT).to(device)\n",
    "model_bert.load_state_dict(torch.load(os.path.join('model', 'bestBert.bin'), weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3ec759-9f84-44ab-9482-ffa8da072b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_bert(model, review):\n",
    "    #tokenizer = MyTokenizer(VOCAB_PATH)\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "    encoding = tokenizer.encode_plus(review,\n",
    "                                          add_special_tokens=True, #Añade los tokens especiales que necesita BERT, [CLS] + [SEP]\n",
    "                                          padding='max_length',  #Añade el pad para que todas las secuencias tengan la misma longitud\n",
    "                                          truncation=True, #Trunca las secuancias más largas de 512, el BERT solo permite 512 tokens\n",
    "                                          max_length=512,\n",
    "                                          return_token_type_ids=False,  #Devuelve si un token pertenece a la primera o a la segunda secuencia\n",
    "                                          return_attention_mask=True,\n",
    "                                          return_tensors='pt')\n",
    "\n",
    "    inputs_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    output_model = model(inputs_ids, attention_mask)\n",
    "    preds = torch.argmax(output_model, dim = 1).tolist()\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "335bf204-ca99-45d0-abc6-d39edfd49477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Review', 'Punt_real', 'Punt_pred', 'Prob_real', 'Prob_pred', 'Pred_BERT'])\n",
    "\n",
    "for i, rev in enumerate(reviews):\n",
    "    if abs(values[i] - predictions[i]) >= 3:\n",
    "        res = {\n",
    "            'Review': rev,\n",
    "            'Punt_real': values[i],\n",
    "            'Punt_pred': predictions[i],\n",
    "            'Prob_real': values_prob[i],\n",
    "            'Prob_pred': predictions_prob[i],\n",
    "            'Pred_BERT': get_prediction_bert(model_bert, rev)\n",
    "        }\n",
    "        df.loc[len(df)] = res\n",
    "\n",
    "        \n",
    "df.to_excel('predicciones_modelos.xlsx', index=False)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "999bb6fb-802b-4994-982b-27bfc6eb6659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de datos con una diferencia de 3 o más: 0.059\n"
     ]
    }
   ],
   "source": [
    "print(f\"Porcentaje de datos con una diferencia de 3 o más: {round(len(df)/len(reviews),3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24093e75-5ac9-42cb-945e-b56634b0e777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
